{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CountVectorizer:\n",
    "\n",
    "#     unique_words = set()\n",
    "\n",
    "#     def fit(self, X):\n",
    "#         for x in X:\n",
    "#             for word in x:\n",
    "#                 self.unique_words.add(word)\n",
    "\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         output = np.zeros((len(X), len(self.unique_words)))\n",
    "#         unique_words = list(self.unique_words)\n",
    "#         for idx, x in enumerate(X):\n",
    "#             for word in x:\n",
    "#                 if word in self.unique_words:\n",
    "#                     output[idx, unique_words.index(word)] += 1\n",
    "\n",
    "#         return output\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self, alpha, penalties):\n",
    "        self.alpha = alpha\n",
    "        self.penalties = penalties\n",
    "        self.num_classes = len(penalties)\n",
    "        self.prior_ = None\n",
    "        self.word_likelihood_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples = X.shape[0]\n",
    "        X_by_class = [[x for x, t in zip(X, y) if t == c] for c in np.unique(y)]\n",
    "\n",
    "        self.prior_ = np.array([len(i) / num_samples for i in X_by_class])\n",
    "\n",
    "        word_counts = np.array([np.array(i).sum(axis=0) for i in X_by_class]) + self.alpha\n",
    "        self.word_likelihood_ = word_counts / word_counts.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probabilities = np.zeros(shape=(X.shape[0], self.prior_.shape[0]))\n",
    "\n",
    "        # nested loop goes brughhh\n",
    "        for i, x in enumerate(X):\n",
    "\n",
    "            lk_message = np.zeros(self.prior_.shape[0])\n",
    "            for word in x:\n",
    "                if word != 0.:\n",
    "                    lk_message += np.log(self.word_likelihood_[:, int(word)])\n",
    "\n",
    "            probabilities[i] = lk_message + np.log(self.prior_) + np.log(self.penalties)\n",
    "\n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folders=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_folder(i):\n",
    "    path = \"messages/part\" + str(i)\n",
    "    X, y = list(), list()\n",
    "    \n",
    "    for filename in os.listdir(path):\n",
    "        with open(path + \"/\" + filename, 'r') as file:\n",
    "            subject = list(map(int, file.readline().split()[1:]))\n",
    "            file.readline()\n",
    "            text = list(map(int, file.readline().split()))\n",
    "            corpus = subject + text\n",
    "            X.append(corpus)\n",
    "            y.append(0 if \"legit\" in filename else 1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_gram(l, n):\n",
    "    n_gram = []\n",
    "    for i in range(len(l) - n + 1):\n",
    "        n_gram.append(\"SEP\".join(map(str, l[i:(i + n)])))        \n",
    "    return n_gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(i, n=1):\n",
    "    all_folds = list(range(10))\n",
    "    \n",
    "    X_test, y_test = read_folder(i)\n",
    "    \n",
    "    X_train, y_train = list(), list()\n",
    "    \n",
    "    for f in all_folds:\n",
    "        \n",
    "        if f+1 != i:\n",
    "            X, y = read_folder(f + 1)\n",
    "            \n",
    "            X_train.extend(X)\n",
    "            y_train.extend(y)\n",
    "            \n",
    "    for i in range(len(X_train)):\n",
    "        X_train[i] = create_n_gram(X_train[i], n)\n",
    "        \n",
    "    for i in range(len(X_test)):\n",
    "        X_test[i] = create_n_gram(X_test[i], n)\n",
    "        \n",
    "    assert len(X_train) == len(y_train)\n",
    "    assert len(X_test) == len(y_test)\n",
    "    \n",
    "    assert len(X_train) + len(X_test) == 1090\n",
    "        \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_bayes(alpha, penalties=[1., 1.], n_gram=1):\n",
    "    \n",
    "    \n",
    "    for fold in range(1, num_folders + 1):\n",
    "        X_train, y_train, X_test, y_test = get_fold(fold, n_gram)\n",
    "        \n",
    "        v = CountVectorizer()\n",
    "        \n",
    "        X_train = [\" \".join(x) for x in X_train]\n",
    "        X_test = [\" \".join(x) for x in X_test]\n",
    "        \n",
    "        X_train = v.fit_transform(X_train).toarray()\n",
    "        X_test = v.transform(X_test).toarray()\n",
    "        \n",
    "        print(X_train.shape)\n",
    "        \n",
    "        classifier = NaiveBayesClassifier(alpha, penalties)\n",
    "\n",
    "        classifier.fit(X_train, np.array(y_train))\n",
    "\n",
    "        y_hat = classifier.predict_proba(X_test)\n",
    "        \n",
    "        y_pred = np.argmax(y_hat)\n",
    "        \n",
    "        print((y_pred == y_test).sum() / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_fold(1, 1)\n",
    "\n",
    "v = CountVectorizer()\n",
    "\n",
    "X_train = [\" \".join(x) for x in X_train]\n",
    "X_test = [\" \".join(x) for x in X_test]\n",
    "\n",
    "X_train = v.fit_transform(X_train).toarray()\n",
    "X_test = v.transform(X_test).toarray()\n",
    "\n",
    "classifier = NaiveBayesClassifier(1.0, [1., 1.])\n",
    "\n",
    "classifier.fit(X_train, np.array(y_train))\n",
    "\n",
    "y_hat = classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - np.argmax(y_hat, 1) == y_test).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
